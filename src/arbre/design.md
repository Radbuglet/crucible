# Arbre Design Overview

**Note:** A proof of concept of this model is already implemented in the `legacy/` directory. It is feature-complete but lacks the key optimizations laid out in this document.

**TODO:** *Add examples, clean up doc.*

Arbre is a user space solution to Rust's "efficient inheritance" problem. It implements an object model where:

- Users can compose classes from an arbitrary number of components, with each component potentially containing sub-components.
- Users can define cross-component dependencies at compile time, creating efficient self-referential structures without `Pin` or redundant references.
- Users can cast class instances at runtime with minimal performance overhead.
- Static dispatch is performed as frequently as possible with minimal generics.
- **TODO:** *Summarize remaining aspects*

## Object System

### Inheritance through Components

`Obj` is a trait providing a `RawVTable` which allows users to extract components from the object. Provided components are attached to a `TypedKey`. `TypedKeys` can be independently created using the `new_key($target:ty)` macro or from their target type using the `typed()` static method.

```rust
const TYPE_KEY: TypedKey<u32> = TypedKey::<u32>::typed();
const NEW_KEY: TypedKey<u32> = new_key!(u32);
const NEW_KEY_2: TypedKey<u32> = new_key!(u32);

// Each `TypedKey` instance generated by `new_key` is unique, even if they contain the same type.
assert_ne!(NEW_KEY, NEW_KEY_2);

// However, all `TypedKeys` obtained through the `typed()` static method are the same
assert_eq!(TypedKey::<u32>::typed(), TYPE_KEY);
```

V-tables is stored using a `PerfectMap` (a `HashMap` that has been computed ahead of time such that there are no collisions), making dynamic component resolution really efficient. Since components can be normal objects with fixed implementations, a dynamic fetch to a statically defined component is almost as efficient as an entirely static dispatch.

**TODO:** *Review `PerfectMap` data structure (see below)*

`Obj` implementations are derived from implementations of the `Comp` trait. Unlike `Obj`, `Comp` is not object-safe and is purely declarative. `Comp` has two fields: an associated type called `Root` and an associated constant called `FRAG`. `Root` declares the type of the root `Obj` used to fetch a component. This type must be `Sized`. If the component can operate on any root, the special `Ignored` marker type can be used. The second field, `FRAG` contains a `VTableFrag`. `VTableFrags` are strongly typed variants of the `RawVTable` object. `VTableFrags` are associated, through generics, with the type of the struct being referenced, and the base type of the object root. `VTableFrags` is created through the `vtable` macro, which can attach fields to component keys and import other `VTableFrags` relative to its subfields.

```rust
pub struct MyObject<ROOT = Self> {
	a: MyComponentA<ROOT>,
	b: MyComponentB,
}

impl<ROOT> Comp for MyObject<ROOT> {
	type Root = ROOT;
	
	const FRAG: VTableFrag<Self, Self::Root> = vtable!(Self, {
		self: [Self],
		..a,  // Imports `a`'s `Comp::FRAG` table fragment
		..b(MyComponentB::get_custom_frag(...)),  // Imports `b` using a custom v-table generated procedurally through `get_custom_frag`.
		a: [dyn SomeOtherKey],  // Exposes `a` under yet another key.
	});
}

pub struct MyComponentA<ROOT = Self> {
	_root: PhantomInvariant<ROOT>,
	// ...
}

impl<R> Comp for MyComponentA {
	type Root = ROOT;
	
	const FRAG: VTableFrag<Self, Self::Root> = vtable!(Self, {
		self: [Self, dyn Any],  // self can be accessed through the `Self` and `dyn Any` component keys.
	});
}

pub struct MyComponentB {
	// ...
}

impl MyComponentB {
	pub const fn get_custom_frag(additional_key: TypedKey<Self>) -> Self {
		vtable!(Self, {
			self: [dyn MyKey, { additional_key }],  // self can be accessed through the `additional_key` component key.
		})
	}
}

impl Comp for MyComponentB {
	type Root = Ignored;   // This is unnecessary as `Ignored` is already the default type value.

	// V-Tables can be defined procedurally.
	const FRAG: VTableFrag<Self, Self::Root> = Self::get_custom_frag(TypedKey::<Self>::typed());
}
```

These implementations are rarely written manually, especially if the object requires a statically known root. Most users will use the `class` and `rooted_class` procedural macros as it is significantly less verbose. Here is the equivalent code sample using the two aforementioned macros:

```rust
#[rooted_class(
	self: [Self],
	a: [dyn SomeOtherKey],
	..a,
	..b: { MyComponentB::get_custom_frag(...) },
)]
struct MyObject {
	a: MyComponentA<ROOT>,  // The `ROOT` generic parameter is injected by the macro. Other blocks will have to inject this parameter manually. 
	b: MyComponentB,
}

#[rooted_class(self: [Self, dyn Any])]
struct MyComponentA {
	// ...
}

#[class(..self: { Self::get_custom_frag(Key::<Self>::typed()) })]
struct MyComponentB {
	// ...
}

impl MyComponentB {
	pub const fn get_custom_frag(additional_key: TypedKey<Self>) -> Self {
		vtable!(Self, {
			self: [dyn MyKey, { additional_key }],  // self can be accessed through the `additional_key` component key.
		})
	}
}
```

### Querying

`Obj` is automatically derived on all `Comps` where `Self` is assignable to `Comp::Root`. `ObjExt` is automatically implemented for all objects implementing `Obj` and provides the following component querying methods:

- `try_fetch_key`: The only required method. Fetches components based off the passed `TypedKey`. Returns `None` if the component wasn't present.
- `fetch_key`: Same as `try_fetch_key` but it automatically unwraps the `Option`.
- `fetch_key_unchecked`: Same as `try_fetch_key` but it performs an unchecked `unwrap` on the `Option`, causing UB if the component wasn't present.
- `has_key`: Returns whether the component has the specified `TypedKey`.
- `try_fetch`: Same as `try_fetch_key` except the key is derived from the return type using `TypedKey::typed`.
- `fetch`: Same as `fetch_key` except the key is derived from the return type using `TypedKey::typed`.
- `fetch_key`: Same as `fetch_key_unchecked` except the key is derived from the return type using `TypedKey::typed`.
- `has`: Same as `has_key` except the key is derived from the return type using `TypedKey::typed`.

### Component Dependencies

All of `ObjExt`'s fetch methods return a `CompRef`, a wrapper around the component reference that bundles an additional reference to the `Obj`. `CompRefs` interact with `Comp`'s `Root` field to allow users to safely downcast the `dyn Obj` root reference to the requested root type. Using the arbitrary associated types unstable feature, `CompRef` can be used to safely interact with components which monomorphise the object root.

```rust
pub trait MyComponentProxy {
	fn do_something(self: CompRef<Self>);
}

#[rooted_class(self: [dyn MyComponentProxy])]
pub struct MyComponent {}

impl<ROOT> MyComponentProxy for MyComponent<ROOT> {
	fn do_something(self: CompRef<Self>) {
		let root = self.obj();  // `root` is a concrete type.
		// ...
	}
}

fn do_something(target: &dyn Obj) {
    // We not know the type of `dyn Obj` and thus cannot statically access `MyComponent`. We can, however, access
    // `MyComponentProxy`, which ignores the `ROOT` generic parameter. 
    target.fetch::<dyn MyComponentProxy>().do_something();
}
```

This monomorphization mechanism is central to the static component cross-referencing strategy. By accepting a struct of all component dependencies as a `const` generic parameter, components can effectively request references to other components in a zero-cost way. This strategy is further strengthened by the presence of dynamic typed keys, which can be used to encapsulate components which are depended upon.

There are two macros which facilitate this strategy: the `deps` macro and the `rooted_methods` macro. The `deps` procedural macro creates a struct of `TypedKeys` for every defined dependency as well as some convenience getters that fetch the component directly off a `CompRef`. `rooted_methods` is a procedural macro which wraps an `impl` block and generates the appropriate generic accessor trait.

Here is an example of a component using these two macros to implement this strategy:

```rust
// Notice how `LISTENER_KEY` is not `pub`?
const LISTENER_KEY: TypedKey<dyn Listener> = new_key!(dyn Listener);

#[rooted_class(
    ..my_component,

    // `name` and `age` are O.K. to publish
    name: RefCell<String>,
    age: Cell<u32>,
    
    // `listener` is not
    listener: { LISTENER_KEY },
)]
pub struct MyObject {
    name: RefCell<String>,
    age: Cell<u32>,
    listener: MyListener,
    my_component: MyComponent<ROOT, { MyComponentDeps { listener: LISTENER_KEY, ..MyComponentDeps::default() } }>,
}

pub trait Listener {
    fn do_something(self: Comp<Self>);
}

#[class(self: Self)]
pub struct MyListener;

impl Listener for MyListener {
    fn do_something(self: Comp<Self>) {
       println!("Did something.");
    }
}

#[deps]  // Derives `Default`, wraps all fields in `TypedKey`, and generates accessor methods.
pub struct MyComponentDeps {
	name: RefCell<String>,  // `Default` for a `TypedKey` is equivalent to `TypedKey::typed`.
	age: Cell<u32>,
	listener: dyn Listener,
}

#[rooted_class(self: [dyn MyComponentProxy])]
pub struct MyComponent<const DEPS: MyComponentDeps> {}

#[rooted_methods(pub MyComponentProxy)]
impl<const DEPS: MyComponentDeps> MyComponent<{DEPS}> {  // (automatically injects the `ROOT` generic parameter)
	fn do_something(self: CompRef<Self>) {  // All methods are public by default. Specifying their visibility is an error.
		let name = DEPS::name(self);  // CompRef is `Copy`.
		let age = DEPS::age(self);
		let listener = DEPS::listener(self);  // Even though we get a reference to a `dyn` object, monomorphization allows the compiler to properly inline the actual object's type.
		// ...
	}
}
```

**TODO:** *Use asymmetric `TypedKeys` to encapsulate proxy traits.*

**TODO:** *This still needs to be less verbose.*

Monomorphization is not always necessary, however. As stated above, the v-table data structure is extremely efficient, and it can be faster to resolve components from a `dyn Obj` that it is to dynamically dispatch to a code section with a monomorphised object root. In these cases, the dynamic dependency resolution strategy can be used. Unlike static dependency resolution, components using dynamic dependency resolution are neither generic over the root type, nor over the dependency list. Instead, the component ignores the root type and holds a reference to a static value containing the dependency struct.

Here is an example component from the above example rewritten to use this strategy:

```rust
#[deps]  // The same macro can be used for both static and dynamic strategies
pub struct MyComponentDeps {
	name: RefCell<String>,
	age: Cell<u32>,
	listener: dyn Listener,
}

#[class(self: [Self])]
pub struct MyComponent {
	deps: &'static MyComponentDeps,
}

impl MyComponent {
	pub fn do_something(self: CompRef<Self>) {
		let name = self.deps.name(self);  // Invocations to either of these are still relatively efficient
		let age = self.deps.age(self);
		let listener = self.deps.listener(self);  // Unlike the above example, the type of `listener` cannot be monomorphised, requiring dynamic dispatch.
		// ...
	}
}
```

Dynamic dependency resolution is best used when the component doesn't already incur a dynamic method dispatch penalty, the types of dependencies are statically known, or the invocations to dynamic dependencies are in the slow path.

Dispatch on known `Obj` types is always fast, regardless of if you use static or dynamic dependency resolution. 

**TODO:** *Prove that all the dynamic dependencies are present ahead of time, saving a jump.*

### Static Casting

**TODO:** *Rework such that it works better with Rust's type system, especially when it comes to casting existing objects without taking ownership.*

`ObjExt` only has one required method: `try_fetch_key`. This makes it easy for users to define their own component fetch wrappers (e.g. `Node` uses this to implement component querying on node ancestries). `ObjExt` can also be used for a second purpose: implementing static cast wrappers. Using the `comp_trait` macro, users can define a `#[repr(transparent)]` wrapper struct whose `ObjExt` implementation includes checks for specific `TypedKeys` that `unwrap_unchecked` their wrapped component. These wrapper structs, alongside objects implementing `Obj`, implement `SafeObjExt`, an unsafe sub-trait of `ObjExt` that promises that the list of provided components will never change. Wrapper structs can be created from other `SafeObjExt` objects, ensuring that wrappers created from concrete `Objs` or other wrappers will perform the minimum amount of checks required to validate the cast.

## Zero-Cost Locking

Interior mutability is critical for the Arbre object model since only immutable references to components can be obtained. Interior mutability in single-threaded scenarios is a mere weakening of the aliasing model to C++ levels of aliasing guarantees and is thus still reasonably efficient. However, in multi-threaded scenarios, interior mutability mechanisms become super heavyweight, requiring OS super-vision. Luckily, as many ECS implementations have demonstrated, users only typically need per-service lock granularity. We can emulate this locking system in Arbre using singleton ZSTs, which gets passed through `Objs`.

Keys are defined using the `new_lock_key` macro, which defines a marker struct with methods to acquire both mutable (`WriteKey<LockTy>`) and immutable (`ReadKey<LockTy>`) instance versions of it. Lock mutability follows Rust's XOR mutability rules. `WriteKeys` can be transformed into `ReadKeys`. Users can dynamically request multiple `WriteKeys` on a single thread (checked using `ThreadId` and atomics), although it isn't very efficient.

All locks are `Send` and `Sync` although their provided features may vary depending on whether the content type implements these traits.

Here is a list of all the supported lock-based interior mutability mechanisms:

- `LockCell`, which can accept a `ReadKey` to copy the value in the cell or a `WriteKey` to modify the value in the cell.
- `LockRefCell`, which can accept a `ReadKey` to get an immutable reference to the contents so long as it implements `Sync` or a `WriteKey`, which gives the `LockRefCell` normal `RefCell` functionality.

To reduce the verbosity of passing `ReadKeys` and `WriteKeys` around the application, we can pack keys inside an `Obj`. If the required keys are wrapped in a static cast wrapper, fetch logic can be entirely elided making locks effectively zero-cost. `Objs` are more than a useful bundle however, as they can provide dynamic down-casting, which may be required in cases where the type of the bundle gets upcasted.

**TODO:** *Does this model properly promote abstraction flexibility as it relates to user-defined locks?*

## Object-DB references

Arbre memory management is almost entirely handled through `Orc`, an Object-DB managed version of `std::sync::Arc`. Unlike `Arc`, the memory held by `Orc` can be freed while `WeakOrcs` remain alive. This allows us to implement lazily collected weak collections without having to worry about leaking memory. Furthermore, since `WeakOrc` requires neither a custom `Clone` or `Drop` implementation, they can be freely `Copy`'d around with no extra overhead.

## Weak Collections

Weak collections are collections where the elements they contain are lazily and passively collected while searching for an insertion place or as the collection gets queried. The alive status of an object is determined by its implementation of the `Weak::is_alive` trait method. Right now, we plan on implementing the following collections:

- `WeakValue`: an `Option` which resolves to and stores `None` if the object isn't alive.
- `WeakMap`: a `HashMap` where dead `Weak` elements magically disappear.
- `WeakSet`: see above
- `WeakVec`: an ECS-like `Vec` where dead elements get removed during iteration or resizing.

## Nodes

`Nodes` are a component which serve three purposes in Arbre: they can provide dependencies based off the node hierarchy, they can be used for logical group iteration (e.g. replicating a branch of game objects), and they can associate a child's lifetime with its parent's.

Since `Nodes` store the object's parent, users can easily query their ancestors. Coupled with a special `ObjExt` implementation, users can fetch components from their ancestors, implementing a simple and convenient dependency injection system.

`Nodes` contain their descendants in a linked list of `Orc<dyn Obj>`. This enables us to implement a node hierarchy using the same exact object lifetime rules as normal `Orcs`. Coupled with a relative depth variable, users can iterate through a node's descendant list. Because all nodes are `Objs`, users can dynamically cast these children to check if they have a required component, making the node hierarchy perfect for notifying large logically grouped portions of a game world.

Since `Nodes` are present in almost all objects in the game world, `WeakMaps` can use them to implement `Storages`. `Storages` implement an SOA annotation mechanism where an arbitrary object with a `Node` component is mapped to a child object which dies when either the `Storage` or its parent die. The `Storage` is a simple `WeakMap` mapping `WeakOrcs` to the parent to `WeakOrcs` to the children that implements custom `Drop` logic to deparent the contained objects. In cases where the map's value does not require a predictable `Drop` call, `WeakMaps` can be used.

---

# `PerfectMap` Performance

`PerfectMap` can only realistically solve for 16 component v-tables and doing so requires a high `const_eval` step limit. Ideally, we'd find a better algorithm that results in both a speedy lookup and a scalable building algorithm. We'd also like to keep the load factor relatively low although this objective is less critical so long as the maps don't get too big (we should be able to handle ~500 in a 2mb static section).

## Work required for 100% load factor

Currently, `PerfectMap` works by repeatedly randomizing the hashes with an ever-increasing seed and checking if the hash mapping is perfect for the given key set.

The probability of randomly encountering such a mapping is $\frac{n!}{x^x}$ assuming each bucket has an equal probability of being selected.

The probability of being successful after $n$ attempts is $(1-\frac{x!}{x^x})^n$.

The average number of attempts required to perfectly hash $x$ buckets with $a$ success rate is $n=\log_{(1-\frac{x!}{x^x})}(a)$.

This graph is scary and bad.

## Load factor for limited work

The probability of randomly encountering a perfect mapping given $n$ keys and $m$ buckets is $\frac{m!}{m^{n}(m-n)!}$ assuming each bucket has an equal probability of being selected.

**TODO**

## Performance cost of double-layered FHS hashing

**TODO**
